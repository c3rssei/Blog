var tipuesearch = {"pages":[{"title":"Arboles de Decisiones","text":"Descripcion Data Exploration: Es sobre descubrir que es lo que nuestros datos significan estadisticamente y aplicar tecnicas de visualizacion, este paso ser realiza para obtener aspectos importantes del conjunto. Univariado: Se enfoca en el analisis de los atributos uno a uno. Bivariado: Analisa dos atributos en conjunto Si quieres ir directamente a la teoria del arbol de decisiones Go to Aqui! In [1]: #Importacion de librerias import pandas as pd import seaborn as sns import numpy as np import matplotlib.pyplot as plt In [2]: #Cargar los datos data = pd . read_csv ( \"golf-dataset.csv\" ) In [3]: data Out[3]: Outlook Temp Humidity Windy Play Golf 0 Overcast Cool Normal True Yes 1 Overcast Hot High False Yes 2 Overcast Hot Normal False Yes 3 Overcast Mild High True Yes 4 Rainy Cool Normal False Yes 5 Rainy Cool Normal True No 6 Rainy Mild High False Yes 7 Rainy Mild High True No 8 Rainy Mild Normal False Yes 9 Sunny Cool Normal False Yes 10 Sunny Hot High False No 11 Sunny Hot High True No 12 Sunny Mild High False No 13 Sunny Mild Normal True Yes In [4]: #Exploracion de variables para determinar que son, numericas o categoricas data . dtypes Out[4]: Outlook object Temp object Humidity object Windy bool Play Golf object dtype: object In [5]: #Exploracion de variables para determinar si nos enfretamos con registros nulos data . info () <class 'pandas.core.frame.DataFrame'> RangeIndex: 14 entries, 0 to 13 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Outlook 14 non-null object 1 Temp 14 non-null object 2 Humidity 14 non-null object 3 Windy 14 non-null bool 4 Play Golf 14 non-null object dtypes: bool(1), object(4) memory usage: 590.0+ bytes In [6]: #**Exploracion de variables para determinar si nos enfretamos Problemas atipicos y grandes desviaciones** data . describe ( include = \"all\" ) Out[6]: Outlook Temp Humidity Windy Play Golf count 14 14 14 14 14 unique 3 3 2 2 2 top Sunny Mild Normal False Yes freq 5 6 7 8 9 Analisis Univariado Parte del analisis univariado incluye realizar tablas de frecuencia para observar que tan recurrentes son las categorias. Como son atributos categoricos lo unico que podemos hacer es generar graficos pie o bar y tablas de frecuencia. Para realizar la tabla, creo un nuevo dataframe llamado outlook, mediante el metodo group by que agrupa los datos creando un nuevo indice en este caso sera el atributo outlook, mediante agg creamos una nueva columna que almacena el conteo de los atributos. In [7]: outlook = data . groupby ( \"Outlook\" ) . agg ( Frecuencia = ( \"Outlook\" , \"count\" )) outlook [ \"Frecuencia Acumulada\" ] = outlook [ \"Frecuencia\" ] . cumsum () outlook [ \"Frecuencia Relativa\" ] = outlook [ \"Frecuencia\" ] / 14 outlook Out[7]: Frecuencia Frecuencia Acumulada Frecuencia Relativa Outlook Overcast 4 4 0.285714 Rainy 5 9 0.357143 Sunny 5 14 0.357143 In [41]: plt . subplots ( figsize = ( 15 , 15 )) sns . set_palette ( \"hls\" , 8 ) plt . subplot ( 2 , 2 , 1 ) ax = data [ \"Outlook\" ] . value_counts () . plot . pie ( legend = True , autopct = \" %1.1f%% \" ) ax . set ( title = \"Outlook\" , ylabel = \"\" ) plt . subplot ( 2 , 2 , 2 ) sns . countplot ( x = data [ \"Outlook\" ]) Out[41]: <matplotlib.axes._subplots.AxesSubplot at 0x7f38bd8c5b38> In [48]: temp = data . groupby ( \"Temp\" ) . agg ( Frecuencia = ( \"Temp\" , \"count\" )) temp [ \"Frecuencia Absoluta\" ] = temp [ \"Frecuencia\" ] . cumsum () temp [ \"Frecuencia Relativa % \" ] = round (( temp [ \"Frecuencia\" ] / 14 ) * 100 , 2 ) temp Out[48]: Frecuencia Frecuencia Absoluta Frecuencia Relativa % Temp Cool 4 4 28.57 Hot 4 8 28.57 Mild 6 14 42.86 In [51]: plt . subplots ( figsize = ( 10 , 10 )) plt . subplot ( 2 , 2 , 1 ) #Fila,columna, indice data [ \"Temp\" ] . value_counts () . plot . pie ( legend = True , autopct = \" %1.1f%% \" ) plt . subplot ( 2 , 2 , 2 ) sns . countplot ( data [ \"Temp\" ]) Out[51]: <matplotlib.axes._subplots.AxesSubplot at 0x7f38bd547d30> In [54]: humidity = data . groupby ( \"Humidity\" ) . agg ( Frecuencia = ( \"Humidity\" , \"count\" )) humidity [ \"Frecuencia Absotula\" ] = humidity [ \"Frecuencia\" ] . cumsum () humidity [ \"Frecuencia Relativa\" ] = round (( humidity [ \"Frecuencia\" ] / 14 ) * 100 , 2 ) humidity Out[54]: Frecuencia Frecuencia Absotula Frecuencia Relativa Humidity High 7 7 50.0 Normal 7 14 50.0 In [57]: plt . subplots ( figsize = ( 10 , 10 )) plt . subplot ( 2 , 2 , 1 ) #Fila,columna, indice data [ \"Humidity\" ] . value_counts () . plot . pie ( legend = True , autopct = \" %1.1f%% \" ) plt . subplot ( 2 , 2 , 2 ) sns . countplot ( data [ \"Humidity\" ]) Out[57]: <matplotlib.axes._subplots.AxesSubplot at 0x7f38bd51bac8> In [60]: windy = data . groupby ( \"Windy\" ) . agg ( Frecuencia = ( \"Windy\" , \"count\" )) windy [ \"Frecuencia Absoluta\" ] = windy [ \"Frecuencia\" ] . cumsum () windy [ \"Frecuencia Relativa\" ] = round (( windy [ \"Frecuencia\" ] / 14 ) * 100 , 2 ) windy Out[60]: Frecuencia Frecuencia Absoluta Frecuencia Relativa Windy False 8 8 57.14 True 6 14 42.86 In [63]: plt . figure ( figsize = ( 10 , 10 )) plt . subplot ( 2 , 2 , 1 ) windy [ \"Frecuencia\" ] . plot . pie ( legend = True , autopct = \" %1.1f%% \" ) plt . subplot ( 2 , 2 , 2 ) sns . barplot ( windy . index , windy [ \"Frecuencia\" ]) Out[63]: <matplotlib.axes._subplots.AxesSubplot at 0x7f38bcf573c8> Analisis Bivariado Consiste en el analisis simultaneo de dos variables, explora el concepto de relacion entre las variables (predictor vs target) , Existen tres tipos de analisis Bivariado Numerico & Numerico Categorico & Categorico Numerico & Categorico En el caso de mi dataset es categorico vs categorico , lo que esta compuesto por graficos de barras y el test de chi cuadrado. Para este tipo de analisis chi cuadrado se generan dos hipotesis: hipotesis nula : jugar o no jugar *No* depende del outlook/ wind / humidity/ temp hipotesis alternativa : jugar o no jugar depende del outlook/ wind / humidity/ temp In [66]: pd . crosstab ( data [ \"Outlook\" ], data [ \"Play Golf\" ], margins = True ) Out[66]: Play Golf No Yes All Outlook Overcast 0 4 4 Rainy 2 3 5 Sunny 3 2 5 All 5 9 14 In [69]: plt . figure ( figsize = ( 5 , 5 )) g = sns . countplot ( x = \"Temp\" , data = data , hue = \"Play Golf\" ) In [72]: g = sns . countplot ( x = \"Outlook\" , data = data , hue = \"Play Golf\" ) In [75]: g = sns . countplot ( x = \"Humidity\" , data = data , hue = \"Play Golf\" ) In [78]: g = sns . countplot ( x = \"Windy\" , data = data , hue = \"Play Golf\" ) Test de chi2 para determinar la asociacion entre los atributos(Categoria) Manualmente chicuadrado se calcula con tres pasos: Definir las hipotesis --> listo Construir Tabla de Contingencia Calcular valor de chi cuadrado Tabla de Contingencia La tabla de contingencia se construye con la siguiente formula $E = n * P$ n: Cantidad de elementos en el subconjunto P: Probabilidad la tabla de contingencia se construye en base a la tabla de observados de la siguiente manera: In [81]: observado = pd . crosstab ( data [ \"Outlook\" ], data [ \"Play Golf\" ], margins = True ) print ( observado ) #e1 = 14*((observado[\"All\"][\"Overcast\"]/14 )*(observado[\"Yes\"][\"All\"]/14)) Play Golf No Yes All Outlook Overcast 0 4 4 Rainy 2 3 5 Sunny 3 2 5 All 5 9 14 La tabla de contigencia se construye de la siguiente manera: Tabla de contigencia Play Golf No Yes Overcast E1 = 14 x p(overcast|no) = 14 * p(overcast)* p(no) = 14 * (4/14)* (5/14) = 1.42 E2 = 14 x p(overcast|yes) = 14 * p(overcast)* p(yes) = 14 * (4/14)* (9/14) = 2.57 Rainy E3 = 14 x p(rainy|no) = 14 * p(rainy)* p(no) = 14 * (5/14)* (5/14) = 1.78 E4 = 14 x p(rainy|yes) = 14 * p(rainy)* p(yes) = 14 * (5/14)* (9/14) = 3.12 Sunny E5 = 14 x p(sunny|no) = 14 * p(sunny)* p(no) = 14 * (5/14)* (5/14) = 1.78 E6 = 14 x p(sunny|yes) = 14 * p(sunny)* p(no) = 14 * (5/14)* (9/14) = 3.12 Calcular Chi cuadrado $\\sum{(E-O)**2/E}$ overcast|no = (0- E1)** 2/E1 = (0-1.42)** 2/1.42 = 2.86 overcast|yes = (4 - 2.57)**2/2.57= 5.25 rainy|no =(2-1.78)**2/1.78 = 0.086 rainy|yes=(3-3.12)**2/3.12 = 0.044 sunny|no=(3-1.78)**2/1.78=2.64 sunny|yes=(2-3.12)**2/3.12=3.91 $\\sum{(E-O)**2/E}$ = 14.79 Teniendo en consideracion un alpha de 0.05 ; $df = (nºfilas-1)(nºcolumnas-1)$ df=3-1 * 2-1 = 2 busco el valor en la tabla de chi cuadrado Link Tabla chi=5.99 como el corte de la region es en el punto 5.99 el valor 14.79 cae fuera de la region de aceptacion de h0 entonces aceptamos la hiptesis alternativa que indica que existe relacion entre el target y outlook. Scipy proporciona un metodo que realiza esto y es de la siguiente manera In [84]: from scipy.stats import chi2_contingency observado = pd . crosstab ( data [ \"Outlook\" ], data [ \"Play Golf\" ]) chi , pvalue , df , expected = chi2_contingency ( observado ) print ( \"Outlook vs Play Golf \\n \" ) print ( \"valor de chi cuadrado :\" , chi ) print ( \"valor p o punto de corte:\" , pvalue ) print ( \"grados de libertad:\" , df ) print ( \"\" ) print ( \"Tabla de contingencia \\n \" , expected ) Outlook vs Play Golf valor de chi cuadrado : 3.5466666666666664 valor p o punto de corte: 0.16976615743981122 grados de libertad: 2 Tabla de contingencia [[1.42857143 2.57142857] [1.78571429 3.21428571] [1.78571429 3.21428571]] In [87]: observado = pd . crosstab ( data [ \"Temp\" ], data [ \"Play Golf\" ]) chi , pvalue , df , expected = chi2_contingency ( observado ) print ( \"Temp vs Play Golf \\n \" ) print ( \"valor de chi cuadrado :\" , chi ) print ( \"valor p o punto de corte:\" , pvalue ) print ( \"grados de libertad:\" , df ) print ( \"\" ) print ( \"Tabla de contingencia \\n \" , expected ) Temp vs Play Golf valor de chi cuadrado : 0.5703703703703703 valor p o punto de corte: 0.7518750053142591 grados de libertad: 2 Tabla de contingencia [[1.42857143 2.57142857] [1.42857143 2.57142857] [2.14285714 3.85714286]] In [90]: observado = pd . crosstab ( data [ \"Humidity\" ], data [ \"Play Golf\" ]) chi , pvalue , df , expected = chi2_contingency ( observado ) print ( \"Humidity vs Play Golf \\n \" ) print ( \"valor de chi cuadrado :\" , chi ) print ( \"valor p o punto de corte:\" , pvalue ) Humidity vs Play Golf valor de chi cuadrado : 1.2444444444444445 valor p o punto de corte: 0.2646162170835855 In [93]: observado = pd . crosstab ( data [ \"Windy\" ], data [ \"Play Golf\" ]) chi , pvalue , df , expected = chi2_contingency ( observado ) print ( \"Windy vs Play Golf \\n \" ) print ( \"valor de chi cuadrado :\" , chi ) print ( \"valor p o punto de corte:\" , pvalue ) Windy vs Play Golf valor de chi cuadrado : 0.16203703703703703 valor p o punto de corte: 0.687287949348002 Resumen Outlook vs Play Golf Se acepta la Hipotesis Alternativa Temp vs Play Golf Se acepta la Hipotesis nula Humidity vs Play Golf Se acepta la Hipotesis alternativa Windy vs Play Gol Se acepta la Hipotesis nulaf Predecir el futuro Esta parte lo que hace es predicir el futuro mediante el modelamiento, como el target es categorico entonces nos enfrentamos a un problema de clasificacion si el target hubiese sido numerico entonces seria regression Arbol de decision Los arboles de decision son modelos con estructura de arbol, el resultado final es un arbol con nodos de decision y nodos hoja. Existen varios algoritmos que permiten la construccion de un arbol de decisiones yo ocupare ID3 que emplea dos principales formulas matematicas Entropia y information gain . La entropia nos permite calcular la homogeneidad de la muestra, varia de o - 1, mientras mas cercano sea a 1 mas variado sera nuestro conjunto viceversa si es mas cercano a 0 sera mas homogeneo. Entropia del target. E(y) = $\\sum{(-P(Ci)* (log(P(Ci))/log 2)}$ Entropia de los predictores. E(Y,x) = $\\sum{(P(Ci)* E(Ci)}$ In [96]: #Entropia del target #Tabla auxiliar import math golf = data . groupby ( \"Play Golf\" ) . agg ( Frecuencia = ( \"Play Golf\" , \"count\" )) golf E_golf = 0 for i in golf [ \"Frecuencia\" ]: E_golf = E_golf - i / 14 * math . log ( i / 14 , 2 ) print ( \"Entropia Y = \" , round ( E_golf , 2 )) #E_golf = -golf[\"Frecuencia\"]/14*math.log(golf[\"Frecuencia\"],2) Entropia Y = 0.94 In [143]: outlook = pd . crosstab ( data [ \"Outlook\" ], data [ \"Play Golf\" ], margins = True ) #E_golf_outlook = -outlook[\"All\"]/14 +(math.log(outlook[\"Yes\"]/outlook[\"All\"],2) + math.log(outlook[\"No\"]/outlook[\"All\"],2)) labels = set ( list ( data [ \"Outlook\" ])) def Entropia_pred ( observados ): E = 0 aux = 0 for i in labels : if observados [ \"Yes\" ][ i ] == 0 : a = 0 else : a = math . log2 ( float ( observados [ \"Yes\" ][ i ] / observados [ \"All\" ][ i ])) if observados [ \"No\" ][ i ] == 0 : b = 0 else : b = math . log2 ( float ( observados [ \"No\" ][ i ] / observados [ \"All\" ][ i ])) aux = ( observados [ \"All\" ][ i ] / 14 ) * (( - observados [ \"Yes\" ][ i ] / observados [ \"All\" ][ i ] ) * a - ( observados [ \"No\" ][ i ] / observados [ \"All\" ][ i ]) * b ) E = E + aux print ( \"Entropia de Outlook\" , E ) Entropia_pred ( outlook ) Entropia de Outlook 0.6935361388961918 In [102]: temp = pd . crosstab ( data [ \"Temp\" ], data [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Temp\" ])) Entropia_pred ( temp ) Entropia de Outlook 0.9110633930116763 In [105]: hum = pd . crosstab ( data [ \"Humidity\" ], data [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Humidity\" ])) Entropia_pred ( hum ) Entropia de Outlook 0.7884504573082896 In [108]: wind = pd . crosstab ( data [ \"Windy\" ], data [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Windy\" ])) Entropia_pred ( wind ) Entropia de Outlook 0.8921589282623617 Una vez calculadas las entropias se procede a calcular el gain $Information Gain(Y,x)=E(Y)-E(x)$ gain(play golf, Outlook)= E(Play Golf) - E(Play Golf,Outlook) = 0.94 - 0.69 = 0.25 gain(Play Golf,Temp) = 0.94 - 0.73 =0.21 gain(Play Golf, Humidity) = 0.94 - 0.788 =0.15 gain(Play Golf, Windy) = 0.94 - 0.89 =0.05 El gain mas alto corresponde al nodo raiz por ende sera Outlook, ahora filtramos la data por cada una de las categorias de outlook y las trabajamos a parte para encontrar el nodo que viene de la misma manera que lo habiamos hecho In [111]: filter = data [ data [ \"Outlook\" ] == \"Sunny\" ] temp = pd . crosstab ( filter [ \"Temp\" ], filter [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Temp\" ])) Entropia_pred ( temp ) Entropia de Outlook 0.14285714285714285 In [114]: hum = pd . crosstab ( filter [ \"Humidity\" ], filter [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Humidity\" ])) Entropia_pred ( hum ) Entropia de Outlook 0.0 In [117]: wind = pd . crosstab ( filter [ \"Windy\" ], filter [ \"Play Golf\" ], margins = True ) labels = set ( list ( data [ \"Windy\" ])) Entropia_pred ( wind ) Entropia de Outlook 0.3396348215831049 otra vez el gain para determinar que nodo se ubicara despues de outlook == Sunny gain(Play Gol outlook=Sunny,temp) =0.97 - 0.14 gain(Play Golf outlook=Sunny,Windy) = 0.97 - 0.33 gain(Play Golf outlook=Sunny,Humidity) = 0.97 - 0 = 0.97 Entonces el ganador es Humidity In [144]: filtro = data [ data [ \"Outlook\" ] == \"Rainy\" ] temp = pd . crosstab ( filtro [ \"Temp\" ], filtro [ \"Play Golf\" ], margins = True ) labels = set ( list ( filtro [ \"Temp\" ])) Entropia_pred ( temp ) Entropia de Outlook 0.3396348215831049 In [145]: filtro = data [ data [ \"Outlook\" ] == \"Rainy\" ] wind = pd . crosstab ( filtro [ \"Windy\" ], filtro [ \"Play Golf\" ], margins = True ) labels = set ( list ( filtro [ \"Windy\" ])) Entropia_pred ( wind ) Entropia de Outlook 0.0 Entonces calcular el gain seria: Gain(Play Golf Outlook =\"Rainy\", Temp) = 0.97 - 0.95 Gain(Play Golf Outlook =\"Rainy\", Windy) = 0.97 - 0 Dejamos como nodo Windy In [126]: outlook = pd . crosstab ( data [ \"Windy\" ], data [ \"Play Golf\" ]) aux = [] for i in outlook . values : aux . append ( i [ 0 ] + i [ 1 ]) In [129]: outlook [ \"Frecuencia\" ] = aux outlook Out[129]: Play Golf No Yes Frecuencia Windy False 2 6 8 True 3 3 6","tags":"posts","url":"https://c3rssei.github.io/Blog/arboles-de-decisiones.html","loc":"https://c3rssei.github.io/Blog/arboles-de-decisiones.html"},{"title":"Descubrir tu data (Conceptos)","text":"Descripcion Los datos estan construidos por data objects. un data object representa una entidad, en una base de datos medica, los objetos pueden ser pacientes, tambien se conocen como muestras, ejemplos, instancias o objetos. Por ende una fila de una base de datos corresponde a un data object. Referencias: Visualizaciones de datos con Python . https://www.ingeniovirtual.com/tipos-de-graficos-y-diagramas-para-la-visualizacion-de-datos/ https://infogram.com/es/pagina/elige-el-grafico-correcto-visualizacion-datos https://bookdown.org/aquintela/EBE/variables-continuas.html https://blog.adrianistan.eu/estadistica-python-pandas-numpy-scipy-parte-i Atributos Fuente de imagen . Un atributo es un campo de dato, que representa una caracteristica de una muestra, por ejemplo teniendo como muestra un cliente un posible atributo seria el nombre, telefono y asi... Atributos Nominales Nominal significa relativo a nombres , los valores de un atributo nominal son simbolos o nombres de cosas, cada valor representa algun tipo de categoria, por ejemplo el color de pelo, estado civil.. Los atributos nominales tambien pueden ser representados con numeros, por ejemplo el id de un respectivo cliente Atributos Ordinales Un atributo ordinal corresponde a un atributo con un posible sentido de orden o ranking, por ejemplo la talla de ropa que va de xs,s,m,l,xl .... Atributos Continuos Aquellos atributos que son continuos son aquellos que se pueden medir, como por ejemplo la temperatura, la humedad... La distribucion que siguen los atributos continuos pueden ser uniforme, normal, exponencial Atributos Discretos Los atributos discretos son aquellos que se pueden contar teniendo en cuenta un numero finito de cantidades, por ejemplo los años, cantidad de hijos... Medición de la tendencia central Medidas de tendencia central Grafico Fuente de imagen . Promedio la medida mas comun y efectiva para el centro de un conjunto de datos es el promedio. Lo cual corresponde a la sumatoria de los elementos dividos en la cantidad de elementos. El promedio si bien es bastante util, es muy sensible a valores extremos, incluso una pequeña cantidad de datos extremos pueden corromper el promedio. Las cifras de un conjunto de datos que son extremadamente altas o extremadamente bajas en comparación con el resto de las cifras se llaman valores atípicos. Debido a la forma de hacer los cálculos, los valores atípicos altos tienden a subir o bajar la media Para esto se puede calcular La media Truncada lo cual se refiere a remover los valores extremos, por ejemplo podemos quitar del el 2% del top y del bottom de la data. import numpy as np np . mean ( data ) Mediana Para valores asimetricos la mejor medida del centro de los datos es la Mediana La mediana corresponde a el valor medio de una lista de valores ordenados, dejando la misma cantidad de valores a un lado que al otro, la mediana entonces corresponde al valor que separa la parte mas alta de un grafico de la parte mas baja. Lo mas importante para el calculo de la mediana es que los datos este ordenados de manera ascendente o descendente. Si el conjunto de datos contiene un número impar de cifras, elige la que esté exactamente en el centro. Ésa es la mediana. Si el conjunto de datos contiene un número par de cifras, coge las dos del centro y calcula la media para obtener la mediana. import numpy as np np . median ( data ) Moda La moda es el valor que mas se repite dentro del conjunto de datos. a diferencia de la media no se ve afectada por valores atipicos al igual que la mediana. import numpy as np import scipy.stats as stats stats . mode ( data ) Desviacion La desviacion es una medicion que indica que tan dispersos son los datos, o que tan alejados estan de la media, \"La desviación estándar puede ser difícil de interpretar como número aislado. Básicamente, una desviación estándar pequeña significa que la mayoría de los valores del conjunto de datos están próximos a la media de ese conjunto, y una desviación estándar grande significa que la mayoría de los valores del conjunto de datos están más alejados de la media\". (Estadisticas para dummies) import numpy as np import scipy.stats as stats np . std ( data ) Representacion grafica La representacion grafica de las variables variara segun lo que se quiera observar: 1. Comparacion: el objetivo es comparar atributos, puede ser un grafico de barras o puntos. 2. Relaciones: Comprender la relacion entre dos o mas atributos. Para determinar si existe un patron entre dos variables numericas. 3. Composicion : Comprender como se compone una variable, diagrama de torta o e barras 4. Distribucion: Esta categoria permite observar como se distribuyen los datos. Suele utilizarse en la exploracion de los datos, el tipo de grafico dependera a que tipo de variable corresponda el atributo, ya sea cuantitativo o cualitativo. Los atributos categoricos pueden ser representados por un grafico de sectores o Torta, los cuales son para observar la composicion del atributo, lo ideal es que sean pocas categoricas para que sea mas claro. Tambien se debe considerar el tipo de variable al escoger el grafico. Relaciones Segun la ayuda de eleccion de graficos, las relaciones son mediante graficos de dispersion o de burbujas. entre las dos variables continuas del conjunto Ejemplo : Precio vs Puntos. Distribucion Los gráficos de distribución/histogramas se usan para conocer la frecuencia de los como valores de una variable y responden a preguntas del estilo: ¿Número de clientes qué tengo por grupo de edad? ¿Cuántos días tardan nuestros pagos? Si la representación es de una única variable y son pocos los datos que hay se utiliza gráficos de barras (Bar histogram). Por ejemplo: Número de habitantes por Comunidad Autónoma. Si la representación es de una única variable y hay muchos datos se utilizan gráfico lineales (Line histogram). Si se quiere representar dos variables hay varias opciones como utilizar gráfico de Scatter plot o de barras con distinto color o varios gráficos. Extraido de --> analitica-de-datos-con-python-y-sofia2-14-graficos-de-distribucion . 1 Comparacion A traves del tiempo o entre categorias. En este tipo de graficos se utiliza principalmente el grafico de barras, es necesario que al menos uno de los ejes sea numerico Histogramas si la variable es numerica entonces es llamado histograma, la variable x esta dento de rangos, lo usual es que los rangos sean iguales, dentro de cada rango se despliega la barra con la cantidad de observaciones en ese rango. plt . figure ( figsize = ( 12 , 8 )) # Tamaño de la figura data [ data [ \"Precio\" ] < 200 ][ \"Precio\" ] . plot . hist () idem sns.distplot() Boxplot los graficos de tipo boxplot permiten Visualizar una variable numerica , utila valores Cuartiles , Extremos , valores raros o outiers Pivot Table Similar a las tablas temporales de sql, permite seleccionar ciertos atributos del conjunto de datos, agrupa en base a un indice mediante el parametro index , a su vez pueden mostrar estimadores estadisticos ya sea promedio o un conjunto de estos. pd.pivot_table(index=[\"Atributo\",\"Atributo2\",\"Atributo n\"]) pd.pivot_table(index,values=\"Atributo\",aggfunc=[\"mean\",np.median]) a su vez la tabla generada permite hacerle un query tab.query(\"Variedad ==['Agiorgitiko']\") Catplot Catplot es un tipo de grafico de dispersion categorica.","tags":"misc","url":"https://c3rssei.github.io/Blog/descubrir-tu-data-conceptos.html","loc":"https://c3rssei.github.io/Blog/descubrir-tu-data-conceptos.html"}]};